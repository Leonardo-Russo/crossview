{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crossview - Autoencoder\n",
    "\n",
    "\n",
    "***Useful Links:***\n",
    "- [***report***](https://www.overleaf.com/project/661be733fb018b56f8400782)\n",
    "- [keras implementation 2024](https://www.analyticsvidhya.com/blog/2023/07/mnist-image-reconstruction-using-an-autoencoder/)\n",
    "- [reference decoder](https://github.com/ugo-nama-kun/conv_ae/blob/main/ae.py)\n",
    "\n",
    "***To Do's:***\n",
    "- data augmentation\n",
    "- make it so that metrics are stored\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "from tqdm import tqdm\n",
    "from torchvision.transforms.functional import to_tensor, to_pil_image\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import timm\n",
    "from utils import *\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "\n",
    "# # To Do's:\n",
    "# - make it so that the metrics are storable\n",
    "\n",
    "\n",
    "# # Set the device\n",
    "# !export CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "image_channels = 3          # for RGB images\n",
    "image_size = 224            # assuming square images\n",
    "hidden_dims = 512           # hidden dimensions\n",
    "output_dims = 100           # size of phi\n",
    "batch_size = 64\n",
    "shuffle = True\n",
    "\n",
    "\n",
    "# Select device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"using device: {device}\")\n",
    "\n",
    "# Initialize Encoder and Decoder\n",
    "encoder = ViTEncoder(out_features=output_dims, model_name='dinov2_vitl14_reg_lc').to(device)\n",
    "decoder = Decoder(input_dims=output_dims, hidden_dims=hidden_dims, output_channels=3, initial_size=7).to(device)\n",
    "# encoder = Encoder(latent_dim=output_dims).to(device)\n",
    "print(encoder, decoder)\n",
    "\n",
    "# Optimizer and Loss Function\n",
    "learning_rate = 1e-3\n",
    "optimizer = optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=learning_rate)\n",
    "criterion = nn.HuberLoss()\n",
    "# criterion = CombinedLoss(device=device)\n",
    "# criterion = nn.MSELoss()\n",
    "# criterion = PerceptualLoss().to(device)\n",
    "\n",
    "# Transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.CenterCrop((image_size, image_size)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Define the Datasets\n",
    "train_dataset = CustomDataset('dataset/train', transform=transform)\n",
    "val_dataset = CustomDataset('dataset/val', transform=transform)\n",
    "\n",
    "# Define the DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=4)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "\n",
    "# ----- Training ----- #\n",
    "\n",
    "def train(encoder, decoder, train_loader, val_loader, device, criterion, optimizer, epochs=10, save_path='untitled'):\n",
    "\n",
    "    encoder.to(device)\n",
    "    decoder.to(device)\n",
    "\n",
    "    model_path = os.path.join('models', save_path)\n",
    "    metrics_path = os.path.join('models', save_path, 'metrics')\n",
    "    results_path = os.path.join('models', save_path, 'results')\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    os.makedirs(metrics_path, exist_ok=True)\n",
    "    os.makedirs(results_path, exist_ok=True)\n",
    "    save_dataset_samples(train_dataloader, os.path.join(model_path, 'training_samples.png'), num_images=16, title='Training Samples')\n",
    "    save_dataset_samples(val_dataloader, os.path.join(model_path, 'validation_samples.png'), num_images=16, title='Validation Samples')\n",
    "\n",
    "    \n",
    "    # Metrics storage\n",
    "    epochs_data = []\n",
    "    train_loss_data = []\n",
    "    val_loss_data = []\n",
    "    val_psnr_data = []\n",
    "    val_ssim_data = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for images in tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}'):\n",
    "            images = images.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            encoded_imgs = encoder(images)\n",
    "            decoded_imgs = decoder(encoded_imgs)\n",
    "            loss = criterion(decoded_imgs, images)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_loss = running_loss / len(train_loader)\n",
    "        train_loss_data.append(avg_loss)\n",
    "        epochs_data.append(epoch + 1)\n",
    "        \n",
    "        # Validation and metrics collection\n",
    "        val_loss, val_psnr, val_ssim = validate(encoder, decoder, val_loader, epoch, results_path, criterion, device)\n",
    "        val_loss_data.append(val_loss)\n",
    "        val_psnr_data.append(val_psnr)\n",
    "        val_ssim_data.append(val_ssim)\n",
    "\n",
    "        # Plotting the metrics\n",
    "        plot_metrics(epochs_data, train_loss_data, val_loss_data, val_psnr_data, val_ssim_data, metrics_path)\n",
    "        \n",
    "        # Save the Model\n",
    "        torch.save(encoder.state_dict(), os.path.join(model_path, f'encoder_epoch_{epoch+1}.pth'))\n",
    "        torch.save(decoder.state_dict(), os.path.join(model_path, f'decoder_epoch_{epoch+1}.pth'))\n",
    "\n",
    "\n",
    "def validate(encoder, decoder, loader, epoch, results_path, criterion, device):\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    validation_loss = 0.0\n",
    "    total_psnr = 0.0\n",
    "    total_ssim = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images in loader:\n",
    "            images = images.to(device)\n",
    "            encoded_imgs = encoder(images)\n",
    "            decoded_imgs = decoder(encoded_imgs)\n",
    "            loss = criterion(decoded_imgs, images)\n",
    "            validation_loss += loss.item()\n",
    "\n",
    "            # Calculate PSNR\n",
    "            total_psnr += psnr(images, decoded_imgs)\n",
    "\n",
    "            # Calculate SSIM for each image in the batch\n",
    "            for i in range(images.size(0)):\n",
    "                # print(f\"Max-Min values in original images: {img1.max()} | {img1.min()}\")\n",
    "                # print(f\"Max-Min values in decoded  images: {img2.max()} | {img2.min()}\")\n",
    "                img1 = images[i].squeeze().cpu().numpy()\n",
    "                img2 = decoded_imgs[i].squeeze().cpu().numpy()\n",
    "                ssim_value = ssim(img1, img2, data_range=1, channel_axis=0, win_size=5, gaussian_weights=False)\n",
    "                total_ssim += ssim_value\n",
    "            \n",
    "    with torch.no_grad():\n",
    "        for images in loader:\n",
    "            images = images.to(device)\n",
    "            decoded_imgs = decoder(encoder(images))\n",
    "            break\n",
    "\n",
    "    visualize_reconstruction(images, decoded_imgs, epoch, save_path=results_path)\n",
    "\n",
    "\n",
    "    avg_val_loss = validation_loss / len(loader)\n",
    "    avg_psnr = total_psnr / len(loader)\n",
    "    avg_ssim = total_ssim / (len(loader) * images.size(0))  # Normalize by total number of images\n",
    "    return avg_val_loss, avg_psnr, avg_ssim\n",
    "\n",
    "\n",
    "train(encoder, decoder, train_dataloader, val_dataloader, device, criterion, optimizer, epochs=10, save_path='lDINO + Huber')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dinov2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
